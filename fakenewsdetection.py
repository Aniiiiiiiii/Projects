# -*- coding: utf-8 -*-
"""FakeNewsDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14A4WYAUuEr9rDUteHAfDZ5Om57mAnXE4
"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC #a classifier that works best for text data

'''
TfidfVectorizer takes two matrices TF (Term Frequency) and IDF (Inverse Document Frequency)

idf => metric calculated by logarithm and division
divide the number of documents divided by the number of the documents that contain the term

then we multiply the two matrices to get a score. to get the the most important and distinctive terms of an article.
'''

data = pd.read_csv("news_dataset.csv")

data

#now to encode it into a binary feature

data['fake'] = data['label'].apply(lambda x: 0 if x == "REAL" else 1)

data

x, y = data['text'], data['fake']

x

y

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) #20% of the data should be used for evaluation and 80% for training

len(x_train) #training data

len(x_test) #testing data

vectorizer = TfidfVectorizer(stop_words="english", max_df=0.7)
x_train_vectorized = vectorizer.fit_transform(x_train.astype('U'))
x_test_vectorized = vectorizer.transform(x_test.astype('U'))

x_train_vectorized

clf = LinearSVC()
clf.fit(x_train_vectorized, y_train)

clf.score(x_test_vectorized, y_test) #so we get a 99.4% accuracy on the testing set

len(y_test)  * 0.9946 #out of 746, 741 were labelled correctly

with open("mynews.txt", "r", encoding="utf-8") as f:
  text = f.read()

vectorized_text = vectorizer.transform([text])

clf.predict(vectorized_text)

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def detect_fake_news(news1, news2, threshold):
    # Load news articles into a DataFrame
    df = pd.DataFrame({'news': [news1, news2]})

    # Create a TfidfVectorizer object
    vectorizer = TfidfVectorizer(stop_words='english')

    # Generate the TF-IDF matrix
    tfidf_matrix = vectorizer.fit_transform(df['news'])

    # Compute the Jaccard similarity
    jaccard_sim = cosine_similarity(tfidf_matrix)[0][1]

    # Return True if the Jaccard similarity is below the threshold
    if jaccard_sim < threshold:
        return True
    else:
        return False

# Example usage
news1 = "The moon landing was faked by the government."
news2 = "NASA successfully landed on the moon in 1969."
threshold = 0.6

if detect_fake_news(news1, news2, threshold):
    print("The news articles are likely fake.")
else:
    print("The news articles are likely genuine.")

import re

def tokenize(text):
    """Converts a text string into a list of tokens (words)."""
    text = text.lower()
    tokens = re.findall(r'\b\w+\b', text)
    return set(tokens)

def jaccard_similarity(text1, text2):
    """Calculates the Jaccard similarity coefficient between two sets of tokens."""
    tokens1 = tokenize(text1)
    tokens2 = tokenize(text2)
    intersection = tokens1.intersection(tokens2)
    union = tokens1.union(tokens2)
    return len(intersection) / len(union)

def is_fake_news(text, threshold=0.5):
    """Determines whether a given text string is likely to be fake news."""
    # Load some example fake news articles for comparison
    with open('real_news.txt') as f:
        real_news_articles = f.readlines()

    # Calculate Jaccard similarity between the input text and each fake news article
    similarities = [jaccard_similarity(text, article) for article in real_news_articles]

    # Determine whether the input text is more similar to fake news or real news
    avg_similarity = sum(similarities) / len(similarities)
    return avg_similarity <= threshold

# Example usage:
text = "The Prime Minister of India, Narendra Modi visits Punjab today (April 24, 2023)."
if is_fake_news(text):
    print("This news is likely fake!")
else:
    print("This news seems to be legitimate.")

import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def tokenize(text):
    """Converts a text string into a list of tokens (words)."""
    text = text.lower()
    tokens = re.findall(r'\b\w+\b', text)
    return set(tokens)

def jaccard_similarity(text1, text2):
    """Calculates the Jaccard similarity coefficient between two sets of tokens."""
    tokens1 = tokenize(text1)
    tokens2 = tokenize(text2)
    intersection = tokens1.intersection(tokens2)
    union = tokens1.union(tokens2)
    return len(intersection) / len(union)

def cosine_similarity(text1, text2):
    """Calculates the cosine similarity between two texts."""
    vectorizer = CountVectorizer().fit_transform([text1, text2])
    return cosine_similarity(vectorizer[0][1])

def is_fake_news(text, threshold=0.5):
    """Determines whether a given text string is likely to be fake news."""
    # Load some example fake news articles for comparison
    with open('real_news.txt') as f:
        real_news_articles = f.readlines()

    # Calculate Jaccard and cosine similarities between the input text and each fake news article
    jaccard_similarities = [jaccard_similarity(text, article) for article in real_news_articles]
    cosine_similarities = [cosine_similarity(text, article) for article in real_news_articles]

    # Determine whether the input text is more similar to fake news or real news
    avg_jaccard_similarity = sum(jaccard_similarities) / len(jaccard_similarities)
    avg_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities)

    if avg_jaccard_similarity >= threshold:
        print("Jaccard similarity score: ", avg_jaccard_similarity)
        print("This news is likely fake according to Jaccard similarity!")
    else:
        print("Jaccard similarity score: ", avg_jaccard_similarity)
        print("This news seems to be legitimate according to Jaccard similarity.")

    if avg_cosine_similarity >= threshold:
        print("Cosine similarity score: ", avg_cosine_similarity)
        print("This news is likely fake according to Cosine similarity!")
    else:
        print("Cosine similarity score: ", avg_cosine_similarity)
        print("This news seems to be legitimate according to Cosine similarity.")

# Example usage:
text = "The Prime Minister of India, Narendra Modi visits Punjab today (April 24, 2023)."
is_fake_news(text)

import re
import math
import nltk


def tokenize(text):
    """Converts a text string into a list of tokens (words)."""
    text = text.lower()
    tokens = re.findall(r'\b\w+\b', text)
    return set(tokens)


def jaccard_similarity(text1, text2):
    """Calculates the Jaccard similarity coefficient between two sets of tokens."""
    tokens1 = tokenize(text1)
    tokens2 = tokenize(text2)
    intersection = tokens1.intersection(tokens2)
    union = tokens1.union(tokens2)
    return len(intersection) / len(union)

def cosine_similarity(text1, text2):
    """Calculates the cosine similarity between two texts."""
    tokens1 = tokenize(text1)
    tokens2 = tokenize(text2)

    # Create a set of all unique words in both texts
    all_words = tokens1.union(tokens2)

    # Create vectors of word frequencies for each text
    vector1 = [list(tokens1).count(word) for word in all_words]
    vector2 = [list(tokens2).count(word) for word in all_words]

    # Calculate the dot product and magnitudes of the vectors
    dot_product = sum([vector1[i] * vector2[i] for i in range(len(vector1))])
    magnitude1 = math.sqrt(sum([count**2 for count in vector1]))
    magnitude2 = math.sqrt(sum([count**2 for count in vector2]))

    # Calculate the cosine similarity between the vectors
    if magnitude1 == 0 or magnitude2 == 0:
        return 0
    else:
        return dot_product / (magnitude1 * magnitude2)

def is_fake_news(text, threshold=0.2):
    """Determines whether a given text string is likely to be fake news."""
    # Load some example fake news articles for comparison
    with open('real_news.txt') as f:
        real_news_articles = f.readlines()

    # Calculate Jaccard and cosine similarities between the input text and each fake news article
    jaccard_similarities = [jaccard_similarity(text, article) for article in real_news_articles]
    cosine_similarities = [cosine_similarity(text, article) for article in real_news_articles]

    # Determine whether the input text is more similar to fake news or real news
    avg_jaccard_similarity = sum(jaccard_similarities) / len(jaccard_similarities)
    avg_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities)

    if avg_jaccard_similarity <= threshold:
        print("Jaccard similarity score: ", avg_jaccard_similarity)
        print("This news is likely fake according to Jaccard similarity!")
    else:
        print("Jaccard similarity score: ", avg_jaccard_similarity)
        print("This news seems to be legitimate according to Jaccard similarity.")

    if avg_cosine_similarity <= threshold:
        print()
        print("Cosine similarity score: ", avg_cosine_similarity)
        print("This news is likely fake according to Cosine similarity!")
    else:
        print()
        print("Cosine similarity score: ", avg_cosine_similarity)
        print("This news seems to be legitimate according to Cosine similarity.")

# Example usage:
text = "In a shocking incident, the Gujarat Titans team was found guilty of ball-tampering during their match against Delhi Capitals in TATA IPL 2023. The incident came to light after the match referee received a complaint from the umpires about the ball being tampered with during the match.  According to sources, the Titans' captain had instructed his players to use sandpaper to rough up the ball and create reverse swing, which is against the rules of the game. The Titans had started well in the match, but the ball-tampering incident affected their performance, and they lost the match to the Capitals.  The incident has sparked outrage among fans and experts, with many calling for strict action against the Titans. The IPL governing council has launched an investigation into the incident, and the Titans could face heavy penalties if found guilty.  This incident is a reminder of the infamous ball-tampering scandal involving the Australian team in 2018, which resulted in bans for then-captain Steve Smith, vice-captain D"
is_fake_news(text)